# kubeflow で何ができて何ができないのか

* [スライド](https://www.slideshare.net/shunyaueta/kubeflow-devfest18)

## Lv1 現場で耐えうる精度のモデルを作成する

* データがないと死亡する

## Lv2 機械学習をサービスインさせる

* めちゃくちゃコストがかかる
* モデルの精度の監視
* スループット

* データ収集 -> 特徴量抽出 -> データ検証
* 各種ワークフロー管理
* 推論結果のサービング環境
* マシンリソース管理
* モデル精度のトラッキング

1つのモデルをサービスインすると1エンジニアの1人月

機械学習システム構築に立ちはだかる壁

* 継続的再学習
  * 学習データは常に変わり続ける
* システムには必ず人が介在する
* データは不変の存在ではない
  * DB 構造変わったとか

## Lv3 機械学習モデルが連日連夜数百個走る

* Facebookの機械学習フロー
  * 学習データ -> features -> トレーニング -> (モデル) -> inference
* TensorFlow Extended
  * kubeflowの元になってる論文
  * google が提唱する概念
  * google play のアプリインストールが 2% up

## kubeflow

* k8s で動く機械学習ツールキット
* simple
  * 数々の機能を kubeflow で提供
* portable
  * k8s が動くならどこでも動く
* scalable
  * k8s の機能を使ってスケーラビリティを担保
* いろんなツールキットが入ってる

## Argo

* コンテナワークフローエンジン
* コンテナネイティブ
* CI/CD 可能
* イベントトリガーが絶賛開発中
  * スケジュールトリガーとかはまだない……

## Patchderm

* 複雑なデータパイプラインの処理

## Jupyerhub

* 共同可能な Jupyer Notebook
* データサイエンティストがモデル作成を Notebook で行う
* TensorFlow に分散学習基盤を提供
  * Horovod & OpenMPI もサポート

## モデル: Pytorch, Caffe2, Chainer Operetor

* CRD 形式で TensorFlow 以外のディープラーニングフレームワークジョブを実行可能

## Katib

* ハイパーパラメータチューニング
* コンテナベース
* google Vizier と呼ばれるブラックボックス最適化の手法からインスパイア
* 特定のDLフレームワークに依存しない形でチューニングが可能
* 手法: Random, Grid, Hyperband, Bayesian, Optimization

## TensorFlow Serving

* 推論結果をサービング
* TFの計算グラフで書かれたモデルをC++で書かれたシステムでデリバリー
* Python でのサービングは辛い
* google が開発してるので期待大
* 全ての処理を計算グラフに落とし込む必要があるので辛い
* TFTなどがあるがそれでも辛い
* POCなら Flask が一番お手軽
  * データのETLが楽

## Seldon Core

* 様々なパラダイムの推論結果をサービング
  * TF
  * Scikit-learn
  * R
  * Spark

いろんな言語使ってて収集つかない時に

## ロードマップ

* 12/16 に ver 1.0 をリリース
  * 新しいデータがロードされると継続的な学習
  * モデル評価
  * いいモデルをプロダクションへロードアウト

ほんとにできるの……？

## kubeflowの現状辛いところ

* k8s が辛い
* 各種ツールの学習コストが高い
* 0.2 で各種コンポーネントが出揃ってきたけどまだ不十分

## kubeflowへの期待

* コンテナベースの機械学習システムは新しいパラダイム
* コンテナベースで分離して疎結合
* 各種ワークフローで要求するスペックが全く違う
  * 画像なら GPU, テキストならメモリ
  * 各処理をコンテナで分離してマシンリソースの最適化
* プロダクション投入への高速化
